{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = pd.read_csv(\"data/temperature.csv\")\n",
    "temperatures['Date'] = pd.to_datetime(temperatures['Date'].astype(str), format='%Y%m') #.dt.to_period('M')\n",
    "temperatures['Year'] = temperatures['Date'].dt.year\n",
    "display(temperatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temp = temperatures.groupby(['Year']).agg({'Value':['mean']}).reset_index()\n",
    "avg_temp.columns = ['Year', \"AvgTemp\"]\n",
    "display(avg_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_scatter = sns.scatterplot(data = temperatures, x=\"Anomaly\", y=\"Value\")\n",
    "display(temp_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_timeseries = sns.lineplot(data=avg_temp, x='Year', y='AvgTemp')\n",
    "display(temp_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wildfires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfires = pd.read_csv(\"data/wildfire.csv\")\n",
    "wildfires['Date'] = pd.to_datetime(wildfires['Date'].astype(str), format='%Y%m')#.dt.to_period('M')\n",
    "display(wildfires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfires['Year'] = wildfires['Date'].dt.year\n",
    "avg_fires = wildfires.groupby(['Year']).agg({'Acres Burned': ['sum']}).reset_index()\n",
    "avg_fires.columns = ['Year', \"Acres Burned\"]\n",
    "display(avg_fires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_timeseries = sns.lineplot(data=avg_fires, x='Year', y='Acres Burned')\n",
    "display(fires_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_scatter = sns.scatterplot(data=wildfires, x='Number of Fires', y='Acres Burned')\n",
    "display(wildfire_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_lineplot_nof = sns.lineplot(data=wildfires, x='Date', y='Number of Fires')\n",
    "display(wildfire_lineplot_nof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_lineplot_acres_burned = sns.lineplot(data=wildfires, x='Date', y='Acres Burned')\n",
    "display(wildfire_lineplot_acres_burned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = pd.read_csv(\"data/precipitation.csv\")\n",
    "precipitation['Date'] = pd.to_datetime(precipitation['Date'].astype(str), format='%Y%m')#.dt.to_period('M')\n",
    "precipitation['Year'] = precipitation['Date'].dt.year\n",
    "display(precipitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prec = precipitation.groupby(['Year']).agg({'Value':['mean']}).reset_index()\n",
    "avg_prec.columns = ['Year', \"AvgPrec\"]\n",
    "display(avg_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_timeseries = sns.lineplot(data=avg_prec, x='Year', y='AvgPrec')\n",
    "display(prec_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurricanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurricane = pd.read_csv(\"data/hurricane.csv\")\n",
    "hurricane['Date'] = hurricane['year'].astype(str) + \"-\" + hurricane['month'].astype(str).str.zfill(2) + \"-\" + hurricane['day'].astype(str).str.zfill(2)\n",
    "hurricane['Date'] = pd.to_datetime(hurricane['Date'], format=\"%Y-%m-%d\").dt.to_period('M')\n",
    "display(hurricane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurricane_scatter_status = sns.scatterplot(data=hurricane, x='wind', y='pressure', hue='status')\n",
    "display(hurricane_scatter_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurricane_scatter_category = sns.scatterplot(data=hurricane, x='wind', y='pressure', hue='category')\n",
    "display(hurricane_scatter_category) # This doesn't take into account the NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tornadoes = pd.read_csv(\"data/tornado.csv\")\n",
    "tornadoes['Date'] = pd.to_datetime(tornadoes['Date'].astype(str), format='%Y%m').dt.to_period('M')\n",
    "display(tornadoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tornadoes = pd.read_csv(\"data/1950-2023_actual_tornadoes.csv\")\n",
    "new_tornadoes['Date'] = pd.to_datetime(new_tornadoes['date'], format=\"%Y-%m-%d\").dt.to_period('M')\n",
    "display(tornadoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake = pd.read_csv(\"data/eqint_tsqp.csv\")\n",
    "earthquake_usa = earthquake[(earthquake.COUNTRY == \"USA\") & (earthquake.LONGITUDE < 0)]\n",
    "display(new_tornadoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "from geodatasets import get_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    earthquake_usa, geometry=geopandas.points_from_xy(earthquake_usa.LONGITUDE, earthquake_usa.LATITUDE), crs=\"EPSG:4326\"\n",
    ")\n",
    "print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = geopandas.read_file(get_path(\"naturalearth.land\"))\n",
    "\n",
    "# We restrict to South America.\n",
    "ax = world.clip([-200, 10, -50, 72]).plot(color=\"white\", edgecolor=\"black\")\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax, color=\"red\", markersize=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurricane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurricane = hurricane[hurricane['year'] > 2018]\n",
    "\n",
    "hurricane_storms = hurricane[hurricane['status'] == 'hurricane']['name'].unique() \n",
    "\n",
    "# Filter the dataset to include only those storms\n",
    "hurricane = hurricane[hurricane['name'].isin(hurricane_storms)] # take only names that turnned into a hurricane\n",
    "\n",
    "from shapely.geometry import Point, LineString\n",
    "# Step 2: Create a GeoDataFrame\n",
    "# Create a geometry column with Point objects\n",
    "hurricane['geometry'] = hurricane.apply(lambda row: Point(row['long'], row['lat']), axis=1)\n",
    "gdf = geopandas.GeoDataFrame(hurricane, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# Step 3: Group by hurricane name and create paths\n",
    "# Create a new GeoDataFrame for paths\n",
    "paths = []\n",
    "\n",
    "for name, group in gdf.groupby('name'):\n",
    "    # Ensure the group is sorted by time (year, month, day, hour)\n",
    "    group = group.sort_values(by=['year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    # Create a LineString for the hurricane path\n",
    "    path_line = LineString(group.geometry.tolist())\n",
    "    \n",
    "    # Add the LineString as a new row in the paths list\n",
    "    paths.append({'name': name, 'geometry': path_line})\n",
    "\n",
    "# Convert the paths list into a GeoDataFrame\n",
    "paths_gdf = geopandas.GeoDataFrame(paths, crs='EPSG:4326')\n",
    "\n",
    "# Step 4: Plot the map\n",
    "# Create a base map\n",
    "world = geopandas.read_file(get_path(\"naturalearth.land\"))\n",
    "ax = world.clip([-110, 0, -10, 72]).plot(color='lightgrey', edgecolor='white', figsize=(12, 10))\n",
    "\n",
    "# Plot each hurricane's path with a unique color\n",
    "paths_gdf.plot(ax=ax, column='name', legend=True, cmap='tab10', linewidth=2)\n",
    "gdf.plot(ax=ax, color='black', markersize=10, label=\"Hurricane Points\")\n",
    "\n",
    "plt.title(\"Hurricane Paths\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
